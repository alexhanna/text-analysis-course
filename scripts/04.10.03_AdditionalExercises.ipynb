{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Exercises for 04.10: Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 0\n",
    "We're going to use `corpus`es from the `nltk` package to go through more examples of `Word2Vec`.\n",
    "1. Import the `movie_reviews` corpus from `nltk.corpus`.\n",
    "    - May need to download the actual corpus first if you've never downloaded/imported it before.\n",
    "2. Fit a model to the contents in `movie_reviews`.\n",
    "    - To retrieve the context, simply call `movie_reviews.sents()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('movie_reviews') # This doesn't import movie_reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "1. Find the similarities between different words that might appear in movie reviews\n",
    "    - ex. `speeding` and `cars`.\n",
    "2. For any words you'd like, find the top similar words to it.\n",
    "    - ex. `battle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "1. Play around with the parameters for building the model and see what kind of different results you'll get.\n",
    "\n",
    "### Word2Vec Features\n",
    "<ul>\n",
    "<li>Size: Number of dimensions for word embedding model</li>\n",
    "<li>Window: Number of context words to observe in each direction</li>\n",
    "<li>min_count: Minimum frequency for words included in model</li>\n",
    "<li>sg (Skip-Gram): '0' indicates CBOW model; '1' indicates Skip-Gram</li>\n",
    "<li>Alpha: Learning rate (initial); prevents model from over-correcting, enables finer tuning</li>\n",
    "<li>Iterations: Number of passes through dataset</li>\n",
    "<li>Batch Size: Number of words to sample from data during each pass</li>\n",
    "<li>Worker: Set the 'worker' option to ensure reproducibility</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
