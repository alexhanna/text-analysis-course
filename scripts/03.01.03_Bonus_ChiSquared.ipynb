{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Computing chi-squared and (non-normalized) correlation statistics\n",
    "\n",
    "As a bonus, we will calculate the chi-squared statistic for all of the words in two novels, *Pride and Prejudice* and *Garland for Girls*, and then calculate the non-normalized correlation for two sample words in the corpus.\n",
    "\n",
    "Don't worry if you don't understand all of this. If it helps some of you, great. If it's a bit advanced no problem, this will not be part of any assignment. Stick with me as much as you can.\n",
    "\n",
    "### 0. Document Term Matrix\n",
    "First, I'll create a document term matrix from the two novels. We did this in the tutorial on February 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>1500</th>\n",
       "      <th>15th</th>\n",
       "      <th>1813</th>\n",
       "      <th>1887</th>\n",
       "      <th>18th</th>\n",
       "      <th>20</th>\n",
       "      <th>2001</th>\n",
       "      <th>26th</th>\n",
       "      <th>30</th>\n",
       "      <th>...</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younge</th>\n",
       "      <th>younger</th>\n",
       "      <th>youngest</th>\n",
       "      <th>youngsters</th>\n",
       "      <th>youth</th>\n",
       "      <th>youthful</th>\n",
       "      <th>youths</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>129</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 9901 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  1500  15th  1813  1887  18th  20  2001  26th  30 ...   york  young  \\\n",
       "0    0     0     1     2     0     1   0     0     1   0 ...      1    129   \n",
       "1    1     1     1     0     2     0   1     1     0   1 ...      2    109   \n",
       "\n",
       "   younge  younger  youngest  youngsters  youth  youthful  youths  zip  \n",
       "0       4       29        14           0      9         0       1    0  \n",
       "1       0        7         2           1      9         1       3    1  \n",
       "\n",
       "[2 rows x 9901 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text_list = []\n",
    "#open and read the novels, save them as variables\n",
    "austen_string = open('../data/Austen_PrideAndPrejudice.txt', encoding='utf-8').read()\n",
    "alcott_string = open('../data/Alcott_GarlandForGirls.txt', encoding='utf-8').read()\n",
    "\n",
    "#append each novel to the list\n",
    "text_list.append(austen_string)\n",
    "text_list.append(alcott_string)\n",
    "\n",
    "countvec = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "\n",
    "novels_df = pandas.DataFrame(countvec.fit_transform(text_list).toarray(), columns=countvec.get_feature_names())\n",
    "novels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Chi-Squared for sample words\n",
    "\n",
    "Let's look at the frequency for two words, \"sister\" and \"child\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sister</th>\n",
       "      <th>child</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>218</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sister  child\n",
       "0     218     14\n",
       "1      40     79"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "novels_df[['sister', 'child']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the chi-squared statistic for these two words we need to know the expected frequency, if these two words were used the same in both novels. To do this, we divide the total frequency across both novels by two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129.0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_sister = novels_df['sister'].sum(axis=0)/2\n",
    "expected_sister"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.5"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_child = novels_df['child'].sum(axis=0)/2\n",
    "expected_child"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the chi_squares we subtract the expected frequency for each novel from the actual frequency for each novel, square this value, and divide by the expected frequency, and add the two numbers together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122.8062015503876"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_sister = ((novels_df.loc[0,'sister'] - expected_sister)**2 / expected_sister) + ((novels_df.loc[1,'sister'] - expected_sister)**2 / expected_sister)\n",
    "chi_sister"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.43010752688172"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_child = ((novels_df.loc[0,'child'] - expected_child)**2 / expected_child) + ((novels_df.loc[1,'child'] - expected_child)**2 / expected_child)\n",
    "chi_child"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are large values. Let's try a word that has a much closer frequency across both novels. The result is a much smaller chi-squared statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    14\n",
       "1    11\n",
       "Name: writing, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "novels_df['writing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35999999999999999"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_writes = novels_df['writing'].sum(axis=0)/2\n",
    "chi_writes = ((novels_df.loc[0,'writing'] - expected_writes)**2 / expected_writes) + ((novels_df.loc[1,'writing'] - expected_writes)**2 / expected_writes)\n",
    "chi_writes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Partisan Score\n",
    "\n",
    "Next, we can find the partisan score for our chosen words. We do this simply, by multiplying the word frequency in *Pride and Prejudice* by 1, and multiple the word frequency in *Garland for Girls* by -1, and adding these together. A partisan score above 0 will indicate it's used more often in Austen, a negative score will mean it is used more often in Alcott."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sister_corr = novels_df.loc[0,'sister']*1 + novels_df.loc[1,'sister']*-1\n",
    "sister_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-65"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "child_corr = (novels_df.loc[0,'child']*1) + (novels_df.loc[1,'child']*-1)\n",
    "child_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writing_corr = (novels_df.loc[0,'writing']*1) + (novels_df.loc[1,'writing']*-1)\n",
    "writing_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writes_corr = (novels_df.loc[0,'writes']*1) + (novels_df.loc[1,'writes']*-1)\n",
    "writes_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does a partisan score of 0 mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "Name: writes, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "novels_df['writes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Chi-Squared for every word, using a for-loop\n",
    "\n",
    "Now we can calculate this for each word in our corpus. To do this we have to introduce the for loop. We've seen this before in list comprehension, but we're splitting it out now into multiple lines. To think this intuitively, take this example:\n",
    "\n",
    "For every child that knocks on my door on Halloween I will do the following:\n",
    "1. Ask them what their costume is\n",
    "2. Give them a piece of candy\n",
    "3. Cackle wildly\n",
    "\n",
    "The for loop in Python is intuitively the same. For every element in a list, we want to do something to that element.\n",
    "\n",
    "In this case, we will loop through all columns in our dataframe and calculate the chi-squared statistic. We will then append both the column name (our word) and the chi-squared statistic to a list using .append()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = list(novels_df)\n",
    "chi_list = []\n",
    "\n",
    "for c in columns:\n",
    "    chi_list.append([c,((novels_df.loc[0,c] - novels_df[c].sum(axis=0)/2)**2 / novels_df[c].sum(axis=0)/2) + ((novels_df.loc[1,c] - novels_df[c].sum(axis=0)/2)**2 / novels_df[c].sum(axis=0)/2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['000', 0.25],\n",
       " ['1500', 0.25],\n",
       " ['15th', 0.0],\n",
       " ['1813', 0.5],\n",
       " ['1887', 0.5],\n",
       " ['18th', 0.25],\n",
       " ['20', 0.25],\n",
       " ['2001', 0.25],\n",
       " ['26th', 0.25],\n",
       " ['30', 0.25]]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now sort this list by the second element in each tuple (it's not technically a tuple, but no matter), and print the top 50 \"partisan\" words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['elizabeth', 155.52507836990597],\n",
       " ['mr', 133.99658314350796],\n",
       " ['darcy', 104.5],\n",
       " ['bennet', 81.0],\n",
       " ['bingley', 76.75],\n",
       " ['jane', 52.160493827160494],\n",
       " ['wickham', 48.5],\n",
       " ['collins', 42.549450549450547],\n",
       " ['old', 42.275229357798167],\n",
       " ['lydia', 42.005813953488371],\n",
       " ['catherine', 31.5],\n",
       " ['family', 31.117283950617285],\n",
       " ['mrs', 30.748886414253896],\n",
       " ['sister', 30.7015503875969],\n",
       " ['don', 24.300000000000001],\n",
       " ['replied', 24.288095238095238],\n",
       " ['gardiner', 24.25],\n",
       " ['lizzy', 24.25],\n",
       " ['work', 23.859467455621303],\n",
       " ['gutenberg', 23.25],\n",
       " ['soon', 22.816787003610109],\n",
       " ['longbourn', 22.0],\n",
       " ['rosy', 22.0],\n",
       " ['charlotte', 21.25],\n",
       " ['jenny', 21.0],\n",
       " ['becky', 20.75],\n",
       " ['feelings', 20.544444444444444],\n",
       " ['project', 20.261764705882353],\n",
       " ['ll', 20.011904761904763],\n",
       " ['father', 19.848101265822784],\n",
       " ['ethel', 19.75],\n",
       " ['letter', 19.467557251908396],\n",
       " ['brother', 18.299382716049383],\n",
       " ['netherfield', 18.25],\n",
       " ['lucas', 17.75],\n",
       " ['jessie', 17.5],\n",
       " ['emily', 17.25],\n",
       " ['manner', 17.12037037037037],\n",
       " ['kitty', 17.013888888888889],\n",
       " ['attention', 17.0],\n",
       " ['thing', 16.898058252427184],\n",
       " ['subject', 16.532608695652176],\n",
       " ['think', 16.167832167832167],\n",
       " ['did', 15.92312661498708],\n",
       " ['girl', 15.434065934065934],\n",
       " ['opinion', 15.307971014492754],\n",
       " ['chapter', 15.25],\n",
       " ['immediately', 15.25],\n",
       " ['ruth', 15.25],\n",
       " ['certainly', 15.210526315789474]]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_list.sort(key=lambda x: x[1], reverse=True)\n",
    "chi_list[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise:\n",
    "\n",
    "Calculate the partisan score for each word in the corpus and print the most partisan words for each novel."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
